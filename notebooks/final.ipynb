{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing\n",
    "# List of columns to be combined (2010 to 2017)\n",
    "import pandas as pd\n",
    "biomass_history = pd.read_csv(\"../data/Biomass_History.csv\")\n",
    "columns_to_combine = ['2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017']\n",
    "\n",
    "# Melt the DataFrame to combine the columns into a single column while retaining the year information\n",
    "biomass_data = pd.melt(biomass_history, id_vars=['Index', 'Longitude', 'Latitude'], value_vars=columns_to_combine, var_name='Year', value_name='Value')\n",
    "\n",
    "# Convert the 'Year' column to numeric\n",
    "#biomass_data['Year'] = pd.to_numeric(biomass_data['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'header' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m best_individual \u001b[39m=\u001b[39m tools\u001b[39m.\u001b[39mselBest(population, k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m \u001b[39m# Save the selected depots and refineries to the output DataFrame\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m output_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39mheader)\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m idx, val \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(best_individual):\n\u001b[1;32m     76\u001b[0m     data_type \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdepot_location\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m idx \u001b[39m<\u001b[39m num_depots \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mrefinery_location\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'header' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 4: Optimal Asset Locations\n",
    "# Implement an optimization algorithm to find the optimal locations for preprocessing depots and biorefineries based on the forecasted biomass data and distance matrix. You can use libraries like DEAP or Optuna to implement the optimization algorithm. This step involves defining the optimization problem, constraints, and the cost function based on the biomass forecast and distance data.\n",
    "from deap import algorithms, base, creator, tools\n",
    "\n",
    "# Step 4: Optimal Asset Locations using Genetic Algorithm\n",
    "# ... (Continue from Step 3)\n",
    "from deap import algorithms, base, creator, tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the optimization problem\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "# Define the number of depots and refineries\n",
    "num_depots = 25\n",
    "num_refineries = 5\n",
    "\n",
    "# Define the number of generations and population size for the Genetic Algorithm\n",
    "num_generations = 50\n",
    "population_size = 100\n",
    "\n",
    "\n",
    "# Define the optimization function (cost function) based on the forecasted biomass data and distance matrix\n",
    "def optimization_function(individual):\n",
    "    # individual contains the indices of selected depots and refineries\n",
    "    # Calculate the overall cost using the indices and their respective forecasted biomass data and distance matrix\n",
    "    cost = 0.0\n",
    "\n",
    "    # Get the indices of depots and refineries from the individual\n",
    "    depot_indices = individual[:num_depots]\n",
    "    refinery_indices = individual[num_depots:]\n",
    "\n",
    "    # Check if there are any duplicate depot indices for each location\n",
    "    unique_depot_indices = set(depot_indices)\n",
    "    if len(unique_depot_indices) != num_depots:\n",
    "        # Penalize the cost if there are duplicates\n",
    "        cost += 1000.0  # Adjust the penalty value as needed\n",
    "    \n",
    "    # ... (implement the cost calculation based on the description)\n",
    "\n",
    "    return cost,\n",
    "\n",
    "# Create the toolbox for the Genetic Algorithm\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"indices\", np.random.randint, 0, 2417, num_depots + num_refineries)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low=0, up=2417, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", optimization_function)\n",
    "\n",
    "# Initialize the population for the Genetic Algorithm\n",
    "population = toolbox.population(n=population_size)\n",
    "\n",
    "# Run the Genetic Algorithm\n",
    "for gen in range(num_generations):\n",
    "    # Evaluate the fitness for each individual in the population\n",
    "    fitnesses = [toolbox.evaluate(ind) for ind in population]\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Select the next generation individuals\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if np.random.rand() < 0.5:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if np.random.rand() < 0.2:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # Replace the old population with the offspring\n",
    "    population[:] = offspring\n",
    "\n",
    "# Get the best individual from the final population\n",
    "best_individual = tools.selBest(population, k=1)[0]\n",
    "\n",
    "# Save the selected depots and refineries to the output DataFrame\n",
    "output_data = pd.DataFrame(columns=header)\n",
    "for idx, val in enumerate(best_individual):\n",
    "    data_type = 'depot_location' if idx < num_depots else 'refinery_location'\n",
    "    output_data = output_data.append({\"year\": \"20182019\", \"data_type\": data_type, \"source_index\": val, \"destination_index\": '', \"value\": None}, ignore_index=True)\n",
    "\n",
    "# Save the output to prediction.csv with header\n",
    "output_data.to_csv('../data/optimization_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('merged_file1.csv')\n",
    "\n",
    "# Define the custom sorting order\n",
    "sorting_order = ['20182019,depot_location','20182019,refinery_location', '2018,biomass_forecast', '2019,biomass_forecast']\n",
    "\n",
    "# Map the data_type to an integer based on the custom sorting order\n",
    "df['data_type_order'] = df['year'].astype(str) + ',' + df['data_type']\n",
    "df['data_type_order'] = df['data_type_order'].map({x: i for i, x in enumerate(sorting_order)})\n",
    "\n",
    "# Sort the DataFrame based on the custom sorting order\n",
    "df_sorted = df.sort_values(by=['data_type_order', 'year'], ascending=[True, True])\n",
    "\n",
    "# Drop the temporary column used for sorting\n",
    "df_sorted = df_sorted.drop(columns=['data_type_order'])\n",
    "\n",
    "# Save the sorted DataFrame to a new CSV file\n",
    "df_sorted.to_csv('../data/final2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
